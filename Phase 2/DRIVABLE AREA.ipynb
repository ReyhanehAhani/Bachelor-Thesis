{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"source":["import os\r\n","import cv2\r\n","from tqdm import tqdm\r\n","import torch\r\n","import numpy as np\r\n","from PIL import Image, ImageFilter\r\n","from pathlib import Path\r\n","import albumentations as albu\r\n","import matplotlib.pyplot as plt\r\n","from torch.utils.data import Dataset\r\n","from torch.utils.data import DataLoader\r\n","\r\n","import os\r\n","import cv2\r\n","from tqdm import tqdm\r\n","import torch\r\n","import numpy as np\r\n","from pathlib import Path\r\n","import matplotlib.pyplot as plt\r\n","from torch.utils.data import Dataset, DataLoader\r\n","import torch.nn as nn\r\n","import albumentations as A\r\n","from albumentations.pytorch import ToTensorV2\r\n","import torchvision\r\n","\r\n","!pip install pytorch_warmup torchview\r\n","import pytorch_warmup as warmup\r\n","from torchview import draw_graph"],"outputs":[],"metadata":{"_uuid":"9e51fb04-9a45-4631-a6de-82f736878b34","_cell_guid":"57afd4ba-1405-4888-a7fe-5c2894ea4492","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-10T19:57:49.143492Z","iopub.execute_input":"2023-07-10T19:57:49.143929Z","iopub.status.idle":"2023-07-10T19:57:49.150821Z","shell.execute_reply.started":"2023-07-10T19:57:49.143894Z","shell.execute_reply":"2023-07-10T19:57:49.149706Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["WIDTH = 1280 // 5\r\n","HEIGHT = 720 // 5\r\n","LEARNING_RATE = 0.001\r\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n","BATCH_SIZE = 64\r\n","NUM_EPOCHS = 20\r\n","NUM_WORKERS = 2\r\n","PIN_MEMORY = True\r\n","TRAIN_IMG_DIR = \"/kaggle/input/object-detection-and-drivable-lane-masking/dataset/images/train/\"\r\n","TRAIN_MASK_DIR = \"/kaggle/input/object-detection-and-drivable-lane-masking/dataset/labels/drivable_labels/masks/train/\"\r\n","VAL_IMG_DIR = \"/kaggle/input/object-detection-and-drivable-lane-masking/dataset/images/val/\"\r\n","VAL_MASK_DIR = \"/kaggle/input/object-detection-and-drivable-lane-masking/dataset/labels/drivable_labels/masks/val\""],"outputs":[],"metadata":{"_uuid":"6386d4c1-57d2-4cef-8c78-35729ab16807","_cell_guid":"2d4be81e-4e66-4514-809f-f6c62ec8e3ca","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-10T19:57:49.231979Z","iopub.execute_input":"2023-07-10T19:57:49.232609Z","iopub.status.idle":"2023-07-10T19:57:49.239338Z","shell.execute_reply.started":"2023-07-10T19:57:49.232563Z","shell.execute_reply":"2023-07-10T19:57:49.238370Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import os\r\n","class BDD100K(Dataset):\r\n","    def __init__(\r\n","        self, \r\n","        image_dir, \r\n","        mask_dir,\r\n","        max_samples = 10000,\r\n","        transform = None\r\n","    ):\r\n","        self.images = sorted(tuple(Path(image_dir).glob('*')))\r\n","        self.masks = sorted(tuple(Path(mask_dir).glob('*')))\r\n","        self.samples = min(len(self.images), max_samples)\r\n","        self.epoch = 0\r\n","        \r\n","        self.transform = transform\r\n","    \r\n","    def __getitem__(self, i):\r\n","        if (i - 1) >= self.samples:\r\n","            self.epoch += 1\r\n","        \r\n","        idx = self.epoch * self.samples + i\r\n","        if idx > len(self.images):\r\n","            self.epoch = 0\r\n","            idx = i\r\n","        \r\n","        image = Image.open(self.images[idx]).convert(\"RGB\")\r\n","        mask = Image.open(self.masks[idx]).convert(\"L\")\r\n","        mask = mask.filter(ImageFilter.MinFilter(3))\r\n","\r\n","        image = image.resize((WIDTH, HEIGHT))\r\n","        mask = mask.resize((WIDTH, HEIGHT))\r\n","                \r\n","        image = np.array(image)\r\n","        mask = np.array(mask, dtype=np.float32)\r\n","        \r\n","        mask = mask.max() - mask\r\n","        mask = mask / 255\r\n","        mask[mask > 0] = 1\r\n","        \r\n","        if self.transform:\r\n","            result = self.transform(image=image, mask=mask)\r\n","            image = result['image']\r\n","            mask = result['mask']\r\n","                     \r\n","        return image, mask\r\n","        \r\n","    def __len__(self):\r\n","        return self.samples"],"outputs":[],"metadata":{"_uuid":"bf6ae488-fb04-43db-87f7-812a7c0959e3","_cell_guid":"818941dd-73f2-494a-bb3b-045413f54e60","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-10T19:57:49.728616Z","iopub.execute_input":"2023-07-10T19:57:49.728986Z","iopub.status.idle":"2023-07-10T19:57:49.740741Z","shell.execute_reply.started":"2023-07-10T19:57:49.728956Z","shell.execute_reply":"2023-07-10T19:57:49.739730Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["class DilatedConvBlock(nn.Module):\r\n","    def __init__(self, ch_in, ch_out, dilation=2):\r\n","        super(DilatedConvBlock, self).__init__()\r\n","        self.conv = nn.Sequential(\r\n","            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=True),\r\n","            nn.BatchNorm2d(ch_out),\r\n","            nn.LeakyReLU(inplace=True),\r\n","            \r\n","            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=True),\r\n","            nn.BatchNorm2d(ch_out),\r\n","            nn.LeakyReLU(inplace=True),\r\n","        )\r\n","        \r\n","    def forward(self, x):\r\n","        return self.conv(x)\r\n","    \r\n","class ConvBlock(nn.Module):\r\n","    def __init__(self, ch_in, ch_out):\r\n","        super(ConvBlock, self).__init__()\r\n","        self.conv = nn.Sequential(\r\n","            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\r\n","            nn.BatchNorm2d(ch_out),\r\n","            nn.LeakyReLU(inplace=True),\r\n","            \r\n","            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\r\n","            nn.BatchNorm2d(ch_out),\r\n","            nn.LeakyReLU(inplace=True),\r\n","        )\r\n","        \r\n","    def forward(self, x):\r\n","        return self.conv(x)\r\n","\r\n","\r\n","class UpConvBlock(nn.Module):\r\n","    def __init__(self, ch_in, ch_out):\r\n","        super(UpConvBlock, self).__init__()\r\n","        self.up = nn.Sequential(\r\n","            nn.Upsample(scale_factor=2),\r\n","            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\r\n","            nn.BatchNorm2d(ch_out),\r\n","            nn.LeakyReLU(inplace=True),\r\n","        )\r\n","\r\n","    def forward(self, x):\r\n","        x = self.up(x)\r\n","        return x\r\n","\r\n","\r\n","class AttentionBlock(nn.Module):\r\n","    def __init__(self, F_g, F_l, F_int):\r\n","        super(AttentionBlock, self).__init__()\r\n","        self.W_g = nn.Sequential(\r\n","            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\r\n","            nn.BatchNorm2d(F_int)\r\n","        )\r\n","\r\n","        self.W_x = nn.Sequential(\r\n","            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\r\n","            nn.BatchNorm2d(F_int)\r\n","        )\r\n","\r\n","        self.psi = nn.Sequential(\r\n","            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\r\n","            nn.BatchNorm2d(1),\r\n","            nn.Sigmoid()\r\n","        )\r\n","\r\n","        self.relu = nn.LeakyReLU(inplace=True)\r\n","\r\n","    def forward(self, g, x):\r\n","        g1 = self.W_g(g)\r\n","        x1 = self.W_x(x)\r\n","        psi = self.relu(g1+x1)\r\n","        psi = self.psi(psi)\r\n","\r\n","        return x*psi\r\n","    \r\n","    \r\n","class UpModule(nn.Module):\r\n","    def __init__(self, feature):\r\n","        super(UpModule, self).__init__()\r\n","        self.up = UpConvBlock(feature*2, feature)\r\n","        self.attn = AttentionBlock(feature, feature, feature // 2)\r\n","        self.conv = DilatedConvBlock(feature*2, feature)\r\n","        self.act = nn.LeakyReLU(inplace=True)\r\n","\r\n","    def forward(self, x, skip_connection):\r\n","        x = self.up(x)\r\n","        skip = skip_connection\r\n","\r\n","        if x.shape != skip_connection.shape:\r\n","            x = torchvision.transforms.functional.resize(x, size=skip_connection.shape[2:])\r\n","\r\n","        skip_connection = self.attn(x, skip_connection)\r\n","\r\n","        concat_skip = torch.cat((skip_connection, x), dim=1)\r\n","        x = self.conv(concat_skip)\r\n","        \r\n","        x = torch.add(x, skip)\r\n","        x = torch.add(x, skip_connection)\r\n","        \r\n","        return self.act(x)\r\n","\r\n","class DownModule(nn.Module):\r\n","    def __init__(self, in_channels, feature):\r\n","        super(DownModule, self).__init__()\r\n","        self.down = DilatedConvBlock(in_channels, feature)\r\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\r\n","        \r\n","\r\n","    def forward(self, x):\r\n","        x = self.down(x)\r\n","        skip = x\r\n","        x = self.pool(x)\r\n","\r\n","        return x, skip\r\n","\r\n","\r\n","class AttenUNET(nn.Module):\r\n","    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256]):\r\n","        super(AttenUNET, self).__init__()\r\n","        \r\n","        self.ups = nn.ModuleList()\r\n","        self.downs = nn.ModuleList()\r\n","        \r\n","        down_outputs = 0\r\n","        \r\n","        # Down part of UNET\r\n","        for feature in features:\r\n","            self.downs.append(DownModule(in_channels, feature))\r\n","            in_channels = feature\r\n","        \r\n","                \r\n","        # Up part of UNET\r\n","        for feature in reversed(features):\r\n","            self.ups.append(UpModule(feature))\r\n","\r\n","        self.bottleneck = nn.Sequential(\r\n","            ConvBlock(features[-1], features[-1]*2),\r\n","            ConvBlock(features[-1]*2, features[-1]*2),\r\n","        )\r\n","        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\r\n","\r\n","\r\n","    def forward(self, x):\r\n","        #x = nn.functional.pad(x, (PADDING, PADDING), value=1) # White padding\r\n","        skip_connections = []\r\n","\r\n","        for down in self.downs:\r\n","            x, skip = down(x)\r\n","            skip_connections.append(skip)\r\n","\r\n","        x = self.bottleneck(x)\r\n","        skip_connections = skip_connections[::-1]\r\n","        \r\n","        \r\n","        for i, up in enumerate(self.ups):\r\n","            skip_connection = skip_connections[i]\r\n","            x = self.ups[i](x, skip_connection)\r\n","        \r\n","        y = self.final_conv(x)\r\n","        #y = nn.functional.interpolate(y, size=(HEIGHT, WIDTH)) # Reverse the padding\r\n","        return y"],"outputs":[],"metadata":{"_uuid":"7c5f8af7-8a1d-4f31-aaf9-9530dd28f4d9","_cell_guid":"ba82fb9e-5f24-4c51-bfc9-771df02d26e5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-10T19:57:49.841846Z","iopub.execute_input":"2023-07-10T19:57:49.842443Z","iopub.status.idle":"2023-07-10T19:57:49.869113Z","shell.execute_reply.started":"2023-07-10T19:57:49.842409Z","shell.execute_reply":"2023-07-10T19:57:49.868126Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import albumentations as A\r\n","from albumentations.pytorch import ToTensorV2\r\n","\r\n","train_transforms = A.Compose([\r\n","    A.Rotate(limit=45, p=0.5),\r\n","    A.HorizontalFlip(p=0.5),\r\n","    A.VerticalFlip(p=0.5),\r\n","    A.CoarseDropout(max_holes=40, min_holes=25, \r\n","                    p=0.5,\r\n","                    max_height=30, \r\n","                    max_width=30, fill_value=1),\r\n","    A.Normalize(\r\n","        mean=[0.0, 0.0, 0.0],\r\n","        std=[1.0, 1.0, 1.0],\r\n","        max_pixel_value=255.0\r\n","    ),\r\n","    ToTensorV2(),\r\n","])\r\n","\r\n","val_transforms = A.Compose([\r\n","    A.Normalize(\r\n","        mean=[0.0, 0.0, 0.0],\r\n","        std=[1.0, 1.0, 1.0],\r\n","        max_pixel_value=255.0,\r\n","    ),\r\n","    ToTensorV2(),\r\n","])"],"outputs":[],"metadata":{"_uuid":"671cb2ed-5854-4e7d-b764-48c9662bbf27","_cell_guid":"dc4b1003-0e11-4270-8292-d257aec71e57","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-10T19:57:49.871197Z","iopub.execute_input":"2023-07-10T19:57:49.871539Z","iopub.status.idle":"2023-07-10T19:57:49.887000Z","shell.execute_reply.started":"2023-07-10T19:57:49.871506Z","shell.execute_reply":"2023-07-10T19:57:49.886032Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["def save_checkpoint(state, filename):\r\n","    print(\"=> Saving checkpoint\")\r\n","    torch.save(state, filename)\r\n","\r\n","def load_checkpoint(checkpoint, model):\r\n","    print(\"=> Loading checkpoint\")\r\n","    model.load_state_dict(checkpoint[\"state_dict\"])\r\n","\r\n","def train_fn(loader, model, optimizer, loss_fn, scaler, lr_scheduler, epoch):    \r\n","    loop = tqdm(loader)\r\n","    \r\n","    for batch_idx, (data, targets) in enumerate(loop):\r\n","        data = data.to(device=DEVICE)\r\n","        targets = targets.to(device=DEVICE).unsqueeze(1)\r\n","\r\n","        # forward\r\n","        with torch.cuda.amp.autocast():\r\n","            predictions = model(data)\r\n","            loss = loss_fn(predictions, targets)\r\n","\r\n","        # backward\r\n","        optimizer.zero_grad(set_to_none=True)\r\n","        scaler.scale(loss).backward()\r\n","        scaler.step(optimizer)\r\n","        scaler.update()\r\n","        \r\n","        lr_scheduler.step()\r\n","        \r\n","        # update tqdm loop\r\n","        loop.set_postfix(loss=loss.item(), epoch=epoch, lr=optimizer.param_groups[0][\"lr\"])\r\n","\r\n","def validate_fn(loader, model, loss_fn, device=\"cuda\"):\r\n","    dice_score = 0\r\n","    loss = 0\r\n","    \r\n","    model.eval()\r\n","\r\n","    with torch.cuda.amp.autocast():\r\n","        with torch.no_grad():\r\n","            for x, y in loader:\r\n","                x = x.to(device)\r\n","                y = y.to(device).unsqueeze(1)\r\n","                \r\n","                preds = torch.sigmoid(model(x))\r\n","                preds[preds >= 0.5] = 1\r\n","\r\n","                dice_score += (2 * (preds * y).sum()) / (\r\n","                    (preds + y).sum() + 1e-8\r\n","                )\r\n","                \r\n","                loss += loss_fn(preds, y)\r\n","\r\n","    model.train()\r\n","    dice_score = dice_score / len(loader)\r\n","    loss = loss / len(loader)\r\n","    \r\n","    print(f\"Dice score\\t{dice_score:.3f}\")\r\n","    print(f\"Val loss\\t{loss:.3f}\")\r\n","    \r\n","    \r\n","    return dice_score, loss"],"outputs":[],"metadata":{"_uuid":"417ab05f-383c-4024-9595-47f74a858a41","_cell_guid":"9335c531-e7b9-4768-a31e-b1d2171fcda6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-10T19:57:49.888546Z","iopub.execute_input":"2023-07-10T19:57:49.888896Z","iopub.status.idle":"2023-07-10T19:57:49.903965Z","shell.execute_reply.started":"2023-07-10T19:57:49.888866Z","shell.execute_reply":"2023-07-10T19:57:49.903012Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["def save_checkpoint(state, filename):\r\n","    print(\"=> Saving checkpoint\")\r\n","    torch.save(state, filename)\r\n","\r\n","def load_checkpoint(checkpoint, model):\r\n","    print(\"=> Loading checkpoint\")\r\n","    model.load_state_dict(checkpoint[\"state_dict\"])\r\n","\r\n","def get_loaders(\r\n","    train_dir,\r\n","    train_maskdir,\r\n","    val_dir,\r\n","    val_maskdir,\r\n","    batch_size,\r\n","    train_transform,\r\n","    val_transform,\r\n","    num_workers=4,\r\n","    pin_memory=True,\r\n","):\r\n","    train_ds = BDD100K(\r\n","        image_dir=train_dir,\r\n","        mask_dir=train_maskdir,\r\n","        transform=train_transform,\r\n","        max_samples=10000\r\n","    )\r\n","\r\n","    train_loader = DataLoader(\r\n","        train_ds,\r\n","        batch_size=batch_size,\r\n","        num_workers=num_workers,\r\n","        pin_memory=pin_memory,\r\n","        shuffle=True,\r\n","    )\r\n","\r\n","    val_ds = BDD100K(\r\n","        image_dir=val_dir,\r\n","        mask_dir=val_maskdir,\r\n","        transform=val_transform,\r\n","        max_samples=500\r\n","    )\r\n","\r\n","    val_loader = DataLoader(\r\n","        val_ds,\r\n","        batch_size=batch_size,\r\n","        num_workers=num_workers,\r\n","        pin_memory=pin_memory,\r\n","        shuffle=False,\r\n","    )\r\n","\r\n","    return train_loader, val_loader"],"outputs":[],"metadata":{"_uuid":"6ca9e26e-95a1-4967-b275-0899b97b0cf9","_cell_guid":"2619c053-0a77-4ef6-b7b8-2d9d2e9b8093","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-10T19:57:49.997865Z","iopub.execute_input":"2023-07-10T19:57:49.998137Z","iopub.status.idle":"2023-07-10T19:57:50.005935Z","shell.execute_reply.started":"2023-07-10T19:57:49.998114Z","shell.execute_reply":"2023-07-10T19:57:50.004959Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import torch.cuda.amp as amp\r\n","import torch.nn.functional as F\r\n","\r\n","##\r\n","# version 2: user derived grad computation\r\n","class FocalSigmoidLossFunc(torch.autograd.Function):\r\n","    '''\r\n","    compute backward directly for better numeric stability\r\n","    '''\r\n","    @staticmethod\r\n","    @amp.custom_fwd(cast_inputs=torch.float32)\r\n","    def forward(ctx, logits, label, alpha, gamma):\r\n","        #  logits = logits.float()\r\n","\r\n","        probs = torch.sigmoid(logits)\r\n","        coeff = (label - probs).abs_().pow_(gamma).neg_()\r\n","        log_probs = torch.where(logits >= 0,\r\n","                F.softplus(logits, -1, 50),\r\n","                logits - F.softplus(logits, 1, 50))\r\n","        log_1_probs = torch.where(logits >= 0,\r\n","                -logits + F.softplus(logits, -1, 50),\r\n","                -F.softplus(logits, 1, 50))\r\n","        ce_term1 = log_probs.mul_(label).mul_(alpha)\r\n","        ce_term2 = log_1_probs.mul_(1. - label).mul_(1. - alpha)\r\n","        ce = ce_term1.add_(ce_term2)\r\n","        loss = ce * coeff\r\n","\r\n","        ctx.vars = (coeff, probs, ce, label, gamma, alpha)\r\n","\r\n","        return loss\r\n","\r\n","    @staticmethod\r\n","    @amp.custom_bwd\r\n","    def backward(ctx, grad_output):\r\n","        '''\r\n","        compute gradient of focal loss\r\n","        '''\r\n","        (coeff, probs, ce, label, gamma, alpha) = ctx.vars\r\n","\r\n","        d_coeff = (label - probs).abs_().pow_(gamma - 1.).mul_(gamma)\r\n","        d_coeff.mul_(probs).mul_(1. - probs)\r\n","        d_coeff = torch.where(label < probs, d_coeff.neg(), d_coeff)\r\n","        term1 = d_coeff.mul_(ce)\r\n","\r\n","        d_ce = label * alpha\r\n","        d_ce.sub_(probs.mul_((label * alpha).mul_(2).add_(1).sub_(label).sub_(alpha)))\r\n","        term2 = d_ce.mul(coeff)\r\n","\r\n","        grads = term1.add_(term2)\r\n","        grads.mul_(grad_output)\r\n","\r\n","        return grads, None, None, None\r\n","\r\n","\r\n","class FocalLoss(nn.Module):\r\n","\r\n","    def __init__(self,\r\n","                 alpha=0.25,\r\n","                 gamma=2,\r\n","                 reduction='mean'):\r\n","        super(FocalLoss, self).__init__()\r\n","        self.alpha = alpha\r\n","        self.gamma = gamma\r\n","        self.reduction = reduction\r\n","\r\n","    def forward(self, logits, label):\r\n","        '''\r\n","        Usage is same as nn.BCEWithLogits:\r\n","            >>> criteria = FocalLossV2()\r\n","            >>> logits = torch.randn(8, 19, 384, 384)\r\n","            >>> lbs = torch.randint(0, 2, (8, 19, 384, 384)).float()\r\n","            >>> loss = criteria(logits, lbs)\r\n","        '''\r\n","        loss = FocalSigmoidLossFunc.apply(logits, label, self.alpha, self.gamma)\r\n","        if self.reduction == 'mean':\r\n","            loss = loss.mean()\r\n","        if self.reduction == 'sum':\r\n","            loss = loss.sum()\r\n","        return loss"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["train_loader, val_loader = get_loaders(\r\n","    TRAIN_IMG_DIR,\r\n","    TRAIN_MASK_DIR,\r\n","    VAL_IMG_DIR,\r\n","    VAL_MASK_DIR,\r\n","    BATCH_SIZE,\r\n","    train_transforms,\r\n","    val_transforms,\r\n","    NUM_WORKERS,\r\n","    PIN_MEMORY,\r\n",")\r\n","\r\n","model = AttenUNET(3, 1).to(DEVICE)\r\n","#model = torch.compile(model) # Faster\r\n","\r\n","loss_fn = FocalLoss(gamma=2)\r\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\r\n","num_steps = (len(train_loader) * NUM_EPOCHS)\r\n","ex = lambda x: 0.999 ** x\r\n","lr_lambda = lambda x: ex(x) if ex(x) > 1e-2 else 1e-2\r\n","lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\r\n","scaler = torch.cuda.amp.GradScaler()\r\n"],"outputs":[],"metadata":{"_uuid":"f552aabf-c6b5-4df8-bdbc-974c2e2107c1","_cell_guid":"5d96af92-40b8-4253-bf16-7934fca4debb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-10T19:57:50.016681Z","iopub.execute_input":"2023-07-10T19:57:50.017408Z","iopub.status.idle":"2023-07-10T19:57:54.482403Z","shell.execute_reply.started":"2023-07-10T19:57:50.017376Z","shell.execute_reply":"2023-07-10T19:57:54.481366Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["for x, y in val_loader:\r\n","    with torch.no_grad():\r\n","        x = x.to(DEVICE)\r\n","        y = y.to(DEVICE).unsqueeze(1)\r\n","\r\n","        for i in range(10):\r\n","            plt.figure()\r\n","            plt.imshow(x[i].cpu().permute(1, 2, 0))\r\n","            plt.imshow(y[i].cpu().reshape(144, 256), cmap='gray', alpha=0.5)\r\n","    break"],"outputs":[],"metadata":{"_uuid":"9ca24d89-c7cb-42c9-9e69-74aee1ba3b0a","_cell_guid":"b91cd647-8ac5-4a83-9a5d-feeebfbd7716","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-10T19:57:54.484339Z","iopub.execute_input":"2023-07-10T19:57:54.484725Z","iopub.status.idle":"2023-07-10T19:58:01.334732Z","shell.execute_reply.started":"2023-07-10T19:57:54.484690Z","shell.execute_reply":"2023-07-10T19:58:01.333582Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["max_score = 0.0\r\n","\r\n","for epoch in range(NUM_EPOCHS):\r\n","    train_fn(train_loader, model, optimizer, loss_fn, scaler, lr_scheduler, epoch)\r\n","\r\n","    # check accuracy\r\n","    dice_score, loss = validate_fn(val_loader, model, loss_fn, device=DEVICE)\r\n","    \r\n","    if dice_score > max_score:\r\n","        max_score = dice_score\r\n","        \r\n","        checkpoint = {\r\n","            \"state_dict\": model.state_dict(),\r\n","        }\r\n","        save_checkpoint(checkpoint, \"attn-unet-best.pth.tar\")"],"outputs":[],"metadata":{"_uuid":"f8498998-ae5b-4ed2-814b-e93c80a3a641","_cell_guid":"835ccf70-b443-4491-8123-2ec6a1710625","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-10T19:58:01.336624Z","iopub.execute_input":"2023-07-10T19:58:01.337241Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["model.eval()\r\n","\r\n","for x, y in val_loader:\r\n","    with torch.no_grad():\r\n","        x = x.to(DEVICE)\r\n","        y = y.to(DEVICE).unsqueeze(1)\r\n","        preds = torch.sigmoid(model(x))\r\n","        preds[preds >= 0.5] = 1\r\n","        \r\n","        for i in range(32):\r\n","            plt.figure(figsize=(10, 10))\r\n","            plt.subplot(1, 2, 1)\r\n","            plt.imshow(x[i].cpu().permute(1, 2, 0))\r\n","            plt.imshow(y[i].cpu().reshape(144, 256), cmap='gray', alpha=0.5)\r\n","            \r\n","            plt.subplot(1, 2, 2)\r\n","            plt.imshow(x[i].cpu().permute(1, 2, 0))\r\n","            plt.imshow(preds[i].cpu().reshape(144, 256), cmap='gray', alpha=0.5)\r\n","    break\r\n","model.train()"],"outputs":[],"metadata":{"_uuid":"7078b027-cc2c-4815-8ee7-b43727c8ab84","_cell_guid":"b1c15e51-1f3d-4ec7-82f1-e748dac31711","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true}}]}